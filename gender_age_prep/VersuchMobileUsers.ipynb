{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Data-Mining-Versuch-Mobile-User-Analysis-and-Gender-Age-Group-Prediction\" data-toc-modified-id=\"Data-Mining-Versuch-Mobile-User-Analysis-and-Gender-Age-Group-Prediction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Mining Versuch Mobile User Analysis and Gender-Age-Group Prediction</a></div><div class=\"lev1 toc-item\"><a href=\"#Einführung\" data-toc-modified-id=\"Einführung-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Einführung</a></div><div class=\"lev2 toc-item\"><a href=\"#Kurzbeschreibung:\" data-toc-modified-id=\"Kurzbeschreibung:-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Kurzbeschreibung:</a></div><div class=\"lev2 toc-item\"><a href=\"#Lernziele:\" data-toc-modified-id=\"Lernziele:-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Lernziele:</a></div><div class=\"lev2 toc-item\"><a href=\"#Aufgaben-zur-Vorbereitung\" data-toc-modified-id=\"Aufgaben-zur-Vorbereitung-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Aufgaben zur Vorbereitung</a></div><div class=\"lev1 toc-item\"><a href=\"#Durchführung\" data-toc-modified-id=\"Durchführung-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Durchführung</a></div><div class=\"lev2 toc-item\"><a href=\"#Datenzugriff\" data-toc-modified-id=\"Datenzugriff-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Datenzugriff</a></div><div class=\"lev2 toc-item\"><a href=\"#Deskriptive-Statistik\" data-toc-modified-id=\"Deskriptive-Statistik-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Deskriptive Statistik</a></div><div class=\"lev3 toc-item\"><a href=\"#Verteilung-der-User-über-die-Gender-Age-Gruppen\" data-toc-modified-id=\"Verteilung-der-User-über-die-Gender-Age-Gruppen-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Verteilung der User über die Gender-Age-Gruppen</a></div><div class=\"lev3 toc-item\"><a href=\"#Verteilung-der-User-über-die-Smartphone-Marken\" data-toc-modified-id=\"Verteilung-der-User-über-die-Smartphone-Marken-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Verteilung der User über die Smartphone-Marken</a></div><div class=\"lev2 toc-item\"><a href=\"#Spatio-Temporale-Analyse-des-Verhaltens-einzelner-User\" data-toc-modified-id=\"Spatio-Temporale-Analyse-des-Verhaltens-einzelner-User-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Spatio-Temporale Analyse des Verhaltens einzelner User</a></div><div class=\"lev1 toc-item\"><a href=\"#Feature-Extraction\" data-toc-modified-id=\"Feature-Extraction-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Feature Extraction</a></div><div class=\"lev1 toc-item\"><a href=\"#Gender-Age-Group-Prediction\" data-toc-modified-id=\"Gender-Age-Group-Prediction-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Gender-Age-Group Prediction</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Mobile User Analysis and Gender-Age-Group Prediction\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 04.10.2016\n",
    "* [Download des Jupyter Notebooks (.ipynb)](Data Mining Praktikum.ipynb) Klick auf _Ziel speichern unter_. Im Verzeichnis, in dem das Notebook abgelegt wurde, Konsole öffnen und dort _jupyter notebook_ eingeben.\n",
    "\n",
    "[Übersicht Ipython Notebooks im Data Mining Praktikum](Data Mining Praktikum.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung\n",
    "\n",
    "## Kurzbeschreibung:\n",
    "\n",
    "In diesem Versuch werden die im Rahmen eines Kaggle-Contest [von _TalkingData_ bereitgestellten Daten](https://www.kaggle.com/c/talkingdata-mobile-user-demographics/data) analysiert. Die Daten enthalten für eine große Menge chinesischer User, Angaben zur Marke und Modell des Smartphones und zu den installierten und aktiven Apps. Ziel ist es aus den zur Verfügung stehenden Trainingsdaten ein Modell zu erlernen, das die Klassifikation der User in die jeweilige Gender-Age-Gruppe erlaubt. Für die Lösung dieser Aufgabe müssen sämtliche Schritte der Data Mining Prozesskette implementiert werden:\n",
    "\n",
    "1. Datenbeschaffung und Zugriff\n",
    "2. Datenauswahl: Welche der vorhandenen Daten sind für die gegebene Aufgabe tatsächlich relevant\n",
    "3. Datenbereinigung: Wie wird mit fehlenden und fehlerhaften Daten umgegangen?\n",
    "4. Datentransformation: Wie können aus den vorhandenen Daten informative Mermale gewonnen werden?\n",
    "5. Modellbildung: Unüberwachtes oder überwachtes erlernen eines Modells; Clustering-, Klassifikations- oder Regressionsmodell.\n",
    "6. Evaluation, Visualisierung und Interpretation der Daten/Ergebnisse\n",
    "\n",
    "## Lernziele:\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Zugriff auf Daten in .csv Files\n",
    "* Zugriff auf Daten in SQLite Files\n",
    "* Statistische Analyse und Visualisierung von Daten\n",
    "* Implementierung der oben genannten Data Mining Prozessschritte, insbesondere:\n",
    "\n",
    "    * Feature-Engineering: Berechnung von für die gegebene Aufgabe relevanter Daten aus Rohdaten\n",
    "    * Clustering (unüberwachtes Lernen) \n",
    "    * Klassifikation/Prädiktion (überwachtes Lernen) mit verschiedenen Machine Learning Verfahren\n",
    "    * Evaluation von Klassifikationsverfahren\n",
    "\n",
    "## Aufgaben zur Vorbereitung\n",
    "\n",
    "1. Laden Sie die Daten entweder vom Skripteserver oder direkt von [Kaggle](https://www.kaggle.com/c/talkingdata-mobile-user-demographics/data) herunter und versuchen Sie die Daten anhand dieser [Beschreibung](https://www.kaggle.com/c/talkingdata-mobile-user-demographics/data) zu verstehen.\n",
    "2. In diesem Versuch soll die Gender-Age-Group von Smartphone-Usern vorhergesagt werden. Überlegen Sie sich welche der vorhandenen Daten für diese Vorhersage relevant sein könnten.\n",
    "3. Für die Vorhersage kann ein beliebiger Klassifikationsalgorithmus aus dem Bereich des überwachten Lernens eingesetzt werden. Das Prinzip des überwachten Lernens und das entsprechende Testen des gelernten Modells ist in der unten aufgeführten Abbildung dargestellt. Machen Sie sich mit diesem Prinzip vertraut.\n",
    "\n",
    "4. Für das überwachte Lernen sind gelabelte Daten (Soll-Ausgabe) notwendig. In diesem Versuch ist die Ausgabe die Gender-Age-Group der User. Im File *gender\\_age\\_train.csv* ist für 74645 User (devices) die zugehörigen Gender-Age-Group angegeben. Die Menge aller gelabelten Daten muss für die Modellvalidierung in disjunkte Trainings- und Testpartitionen unterteilt werden. In diesem Versuch kommt sowohl eine einfache Partitionierung in Trainings- und Testdaten als auch eine Kreuzvalidierung zum Einsatz ([KI-Vorlesung](https://www.mi.hdm-stuttgart.de/mib/studium/intern/skripteserver/skripte/Einfuehrung_Kuenstliche_Intelligenz/WS1516/06_PartLernen1.pdf)). Machen Sie sich mit dem Prinzip der Kreuzvalidierung (Abbildung unten) vertraut.\n",
    "\n",
    "5. Den meisten Machine Learning-Algorithmen können kategoriale Parameter nicht direkt übergeben werden. Diese Parameter werden typisch *One-Hot* encodiert. Machen Sie sich mit diesem Prinzip vertraut.\n",
    "\n",
    "6. In diesem Versuch soll ein Multilayer-Perzeptron (MLP) als Klassifikator eingesetzt werden. Machen Sie sich mit dem MLP vertraut. [KI-Vorlesung](https://www.mi.hdm-stuttgart.de/mib/studium/intern/skripteserver/skripte/Einfuehrung_Kuenstliche_Intelligenz/WS1516/09_PartLernen4.pdf), [MLP in Scikit-Learn](http://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
    "\n",
    "**Prinzip überwachtes Lernen und Validierung:**\n",
    "![Prinzip überwachtes Lernen](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/SupervisedLarningSchemaValidation.png \"Überwachtes Lernen Schema\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Prinzip der 10-fachen Kreuzvalidierung:**\n",
    "\n",
    "![Kreuzvalidierung](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/CrossValidation.jpg \"Cross-Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Datenzugriff\n",
    "Die Daten sind in insgesamt 7 .csv Files organisiert (das File sample_submission.csv wird nicht benötigt). Die einzelnen .csv Dateien sind z.T. sehr groß. In diesem Fall bietet es sich an, nicht das ganze File in einen Pandas-Dataframe zu laden, sondern das .csv-File zunächst in eine Datenbank zu schreiben und dann auf diese dediziert zuzugreifen. \n",
    "\n",
    "_Tipp:_ Mit der auf dem Skripteserver bereitgestellten Datei _brandMap.txt_, können die chinesischen Schriftzeichen in den Markennamen übersetzt werden.\n",
    "\n",
    "**Aufgaben:**\n",
    "\n",
    "1. Lesen Sie jedes der .csv Files in chunks von jeweils ca. 20000 Zeilen in einen Pandas Dataframe ein und schreiben Sie die Daten chunk für chunk in eine SQLite Database. Für das Einlesen ist die Pandas-Methode [read_csv()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) mit dem Parameter _chunksize_ zu verwenden. Für das schreiben der Daten aus dem Pandas Dataframe in die SQLite Datenbank ist die Pandas-Methode [to_sql()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html) zu verwenden. Für jedes .csv File soll in der SQLite-DB eine eigene Tabelle angelegt werden. Als DB-connector soll eine engine-Instanz des _SQLAlchemy_-Pakets mit der Methode create\\_engine() angelegt werden. Siehe z.B. [SQLAlchemy Doku](http://docs.sqlalchemy.org/en/latest/core/engines.html).\n",
    "\n",
    "2. Nachdem alle Tabellen der DB angelegt sind, sollen aus jeder Tabelle die ersten 10 Zeilen mit der Pandas Methode [read_sql_query()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_query.html) abgefragt und angezeigt werden. Ausserdem ist für jede Tabelle die Größe (Anzahl der Zeilen) auszugeben.\n",
    "3. Wie viele verschiedene devices befinden sich in der Tabelle, welche die Daten aus gender\\_age\\_train.csv enthält?\n",
    "4. Wie viele verschiedene devices befinden sich in der Tabelle, welche die Daten aus events.csv enthält?\n",
    "5. Wie viele verschiedene devices kommen in beiden dieser Tabellen vor? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Deskriptive Statistik\n",
    "\n",
    "In der obigen Teilaufgabe sollte die Schnittstelle zwischen Pandas Dataframes und Datenbanken (hier SQLite) demonstriert werden. Diese Art von Datenhandling eignet sich besonders im Fall sehr großer Datenmengen, die nicht im Arbeitsspeicher gehalten werden können. Die Dateien in diesem Versuch sind tatsächlich nicht so groß, dass sie nicht als ganzes in Pandas-Dataframes geladen werden könnten. In allen folgenden Teilversuchen ist Ihnen freigestellt, ob Sie mit der Datenbank-Variante oder der in-memory Variante (alle Daten im Pandas-Dataframe) arbeiten.\n",
    "\n",
    "### Verteilung der User über die Gender-Age-Gruppen\n",
    "\n",
    "Die Menge aller User wird in 12 verschiedene Gender-Age-Groups unterteilt. Bestimmen Sie die Verteilung der User in der gender\\_age\\_train-Tabelle über diese 12 Gruppen und viusalisieren Sie diese Verteilung in einem [Matplolib Bar Chart](http://matplotlib.org/api/pyplot_api.html). \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verteilung der User über die Smartphone-Marken\n",
    "\n",
    "1. Bestimmen Sie die Anzahl der verschiedenen Devices und die Anzahl der verschiedenen Marken in der Tabelle *phone\\_brand\\_device\\_model*.\n",
    "\n",
    "2. Fügen Sie dem Pandas Dataframe mit der *gender_age_train*-Tabelle eine Spalte _brand_ hinzu und schreiben Sie in diese Spalte den Markennamen des zur jeweiligen Zeile gehörenden Device.\n",
    "3. Schreiben Sie den um den Markennamen erweiterten Dataframe in ein File *gender\\_age\\_brand\\_train.csv*.\n",
    "4. Bestimmmen Sie mittels der Dataframe-Methode *value_counts()* die Anzahl der Devices pro Marke. \n",
    "5. Stellen Sie diese Verteilung der Devices über die Marken für die 20 häufigsten Marken grafisch mit einem *Matplotlib-bar-chart dar.*\n",
    "6. Untersuchen Sie jetzt die Verteilung der Devices über die Marken pro Gender-Age-Group. Gibt es eine Korrelation zwischen Gender-Age-Group und Häufigkeit der Marken? Überlegen sie sich eine Visualisierung mit der eine derartige Korrelation bestätigt oder widerlegt werden kann. Implementieren Sie die Visualisierung und zeigen Sie anhand dieser Visualisierung mögliche Korrelationen zwischen Gender-Age-Group und Markenhäufigkeit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatio-Temporale Analyse des Verhaltens einzelner User\n",
    "\n",
    "1. Wählen Sie aus der *events*-Tabelle ein Device, für das mindestens 30 events mit zugewiesenen Geokordinaten vorliegen.\n",
    "2. Stellen Sie alle Aufenthaltsorte des zu diesem Device gehörenden Users in einer *gmaps-Heatmap* dar. Informationen hierzu finden Sie in der [gmaps-Doku]( https://github.com/pbugnion/gmaps). Für den Zugriff auf gmaps benötigen Sie einen Google-API-Key (siehe [gmaps authentication](http://jupyter-gmaps.readthedocs.io/en/latest/authentication.html))\n",
    "3. Clustern Sie die 2-dimensionalen Geodaten des ausgewählten Users mit dem [DBSCAN-Algorithmus von scikit-learn](http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html). Die Parameter des Algorithmus sind so zu wählen, dass wesentlich unterschiedliche Orte des Users in unterschiedlichen Clustern landen.\n",
    "4. Stellen Sie den zeitlichen Verlauf der Events des ausgewählten Users im unten dargestellten Stil visuell dar. Auf der horizontalen Achse ist die Zeit relativ zur Zeit des ersten Events in Sekunden dargestellt. Auf der vertikalen Achse ist die Anzahl der bisherigen Events des Users aufgetragen. Mit jedem Event wird der Wert auf der vertikalen Achse um 1 erhöht. Die Farbe der Marker im Graph gibt den Aufenthaltscluster an. Für jeden in der vorigen Teilaufgabe gefundenen Aufenthaltscluster wird eine unterschiedliche Farbe benutzt (Im Beispiel unten wurden nur 2 Cluster gefunden). Diskutieren Sie das Verhalten des Users anhand des Graphs.\n",
    "\n",
    "![Abbildung Zeitliches Auftreten der Events](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/tempbehave.PNG \"Events über der Zeit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anmerkung: In den vorigen Aufgaben war das Vorgehen relativ konkret vorgegeben. In den folgenden Aufgaben sind die Vorgaben bewußt knapp gehalten. Ihre Kreativität ist gefragt.\n",
    "\n",
    "1. Überlegen Sie sich aus welchen Merkmalen, die aus den vorhandenen Daten extrahiert werden können, möglichst gut die Gender-Age-Group vorhergesagt werden kann.\n",
    "2. Extahieren Sie diese Merkmale aus den Daten für möglichst viele (mindestens 20.000) User (devices) aus der Tabelle *gender_age_train*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender-Age-Group Prediction\n",
    "1. In der vorigen Aufgabe wurde für jeden User (device) ein Merkmalsvektor berechnet. Die Menge der Merkmalsvektoren aller User aus der Tabelle *gender_age_train* bildet die Eingabe-Matrix $X$ für die Klassifikationsalgorithmen. Die Soll-Ausgabe Vektor $y$ wird durch die *gender_age_group* der User gebildet. Bringen Sie die Matrix aller Eingabevektoren in eine Form, in der\n",
    "    * alle kategorialen Parameter *One-Hot*-encodiert sind [Scikit-Learn One-Hot-Encoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder).\n",
    "    * alle Merkmale eine Varianz von 1 aufweisen. Benützen Sie hierfür die [Scikit-Learn Methode scale](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale).\n",
    "2. Teilen Sie die Datensätze in $X$ und $y$ in eine Trainings- und eine Testpartition auf - im Verhältnis $3/4$ für Training, $1/4$ für Test. \n",
    "3. Trainieren Sie mit der Trainingspartition ein [Multilayer-Perzeptron](http://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
    "4. Testen Sie das gelernte Modell mit der Testpartition. Für die Auswertung sollte die [Accurracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) und die [Confusion Matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) bestimmt werden. Finden Sie eine Parametereinstellung, die zu einer möglichst guten Accuracy führt. Interpretieren Sie die Confusion Matrix.\n",
    "5. Wenden Sie nun eine [5-fache Kreuzvalidierung](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) an und bestimmen Sie damit eine möglichst gute Parametereinstellung.\n",
    "6. Mit welchen Parametern erzielen Sie die beste Accurracy? Wie hoch ist diese dann? Diskutieren Sie das Ergebnis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
